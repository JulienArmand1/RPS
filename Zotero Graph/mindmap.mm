<?xml version='1.0' encoding='utf-8'?>
<map version="0.9.0"><node TEXT="Articles"><node TEXT="No-regret learning in harmonic games: {Extrapolation} in the face of conflicting interests"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Cycle" /><node TEXT="Exploration" /><node TEXT="Harmonic game" /><node TEXT="Important" /><node TEXT="Mathematics - Optimization and Control" /><node TEXT="Poincaré récurrent" /></node><node TEXT="What is the long-run distribution of stochastic gradient descent? {A} large deviations analysis"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mathematics - Optimization and Control" /><node TEXT="Mathematics - Probability" /><node TEXT="Statistics - Machine Learning" /></node><node TEXT="No-{Regret} {Learning} in {Games} with {Noisy} {Feedback}: {Faster} {Rates} and {Adaptivity} via {Learning} {Rate} {Separation}"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /></node><node TEXT="A universal black-box optimization method with almost dimension-free convergence rate guarantees"><node TEXT="Mathematics - Optimization and Control" /></node><node TEXT="Pick your {Neighbor}: {Local} {Gauss}-{Southwell} {Rule} for {Fast} {Asynchronous} {Decentralized} {Optimization}"><node TEXT="Computer Science - Distributed" /><node TEXT="Parallel" /><node TEXT="and Cluster Computing" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mathematics - Optimization and Control" /></node><node TEXT="Learning in {Games} with {Quantized} {Payoff} {Observations}"><node TEXT="Computer Science - Computer Science and Game Theory" /></node><node TEXT="Nested bandits"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mathematics - Optimization and Control" /></node><node TEXT="Payoff-based learning with matrix multiplicative weights in quantum games"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mathematics - Optimization and Control" /><node TEXT="Quantum Physics" /></node><node TEXT="Explicit {Second}-{Order} {Min}-{Max} {Optimization} {Methods} with {Optimal} {Convergence} {Guarantee}" /><node TEXT="Learning in quantum games"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mathematics - Optimization and Control" /><node TEXT="Quantum Physics" /></node><node TEXT="Exploiting hidden structures in non-convex games for convergence to {Nash} equilibrium"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /></node><node TEXT="Survival of dominated strategies under imitation dynamics"><node TEXT="Computer Science - Computer Science and Game Theory" /></node><node TEXT="A {Quadratic} {Speedup} in {Finding} {Nash} {Equilibria} of {Quantum} {Zero}-{Sum} {Games}"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mathematics - Optimization and Control" /><node TEXT="Quantum Physics" /></node><node TEXT="A {Stochastic} {Variant} of {Replicator} {Dynamics} in {Zero}-{Sum} {Games} and {Its} {Invariant} {Measures}"><node TEXT="Cycle" /><node TEXT="Game Theory" /></node><node TEXT="Learning with contextual information in non-stationary environments"><node TEXT="Non-stationary" /><node TEXT="RPS" /></node><node TEXT="{ConceptExplainer}: {Interactive} {Explanation} for {Deep} {Neural} {Networks} from a {Concept} {Perspective}"><node TEXT="Computer Science - Human-Computer Interaction" /><node TEXT="Demande CCAI phase II" /></node><node TEXT="Bandit {Learning} with {Biased} {Human} {Feedback}" /><node TEXT="Bandit {Algorithms}"><node TEXT="Notes de Cours" /><node TEXT="RL" /><node TEXT="Theory" /></node><node TEXT="Autocurricula and the {Emergence} of {Innovation} from {Social} {Interaction}: {A} {Manifesto} for {Multi}-{Agent} {Intelligence} {Research}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Computer Science - Neural and Evolutionary Computing" /><node TEXT="Quantitative Biology - Neurons and Cognition" /></node><node TEXT="Alignment faking in large language models"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Computation and Language" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Lecture début de projet" /></node><node TEXT="{APRIL}: {Active} {Preference}-learning based {Reinforcement} {Learning}"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Demande CCAI phase II" /></node><node TEXT="Dueling {Posterior} {Sampling} for {Preference}-{Based} {Reinforcement} {Learning}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Demande CCAI phase II" /><node TEXT="Statistics - Machine Learning" /></node><node TEXT="Deep reinforcement learning from human preferences"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Human-Computer Interaction" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Demande CCAI phase II" /><node TEXT="Statistics - Machine Learning" /></node><node TEXT="Deal or {No} {Deal}? {End}-to-{End} {Learning} of {Negotiation} {Dialogues}"><node TEXT="LLM" /><node TEXT="Lecture début de projet" /><node TEXT="Negotiation" /><node TEXT="RL" /><node TEXT="Recommandé Audrey" /></node><node TEXT="Biological {Sequence} {Design} with {GFlowNets}"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Demande CCAI phase II" /><node TEXT="Quantitative Biology - Biomolecules" /></node><node TEXT="Dueling {RL}: {Reinforcement} {Learning} with {Trajectory} {Preferences}"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Demande CCAI phase II" /></node><node TEXT="Evolution with {Opponent}-{Learning} {Awareness}"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Game Theory" /><node TEXT="Important" /><node TEXT="Matrix game" /><node TEXT="Quantitative Biology - Populations and Evolution" /><node TEXT="Quantitative Finance - General Finance" /><node TEXT="RPS" /></node><node TEXT="Neural {Pseudo}-{Label} {Optimism} for the {Bank} {Loan} {Problem}" /><node TEXT="On {Statistical} {Bias} {In} {Active} {Learning}: {How} and {When} {To} {Fix} {It}"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Demande CCAI phase II" /><node TEXT="Statistics - Machine Learning" /></node><node TEXT="Rational and {Convergent} {Learning} in {Stochastic} {Games}"><node TEXT="Cycle" /><node TEXT="Game Theory" /><node TEXT="Mars 2025" /><node TEXT="RPS" /></node><node TEXT="{RLAIF} vs. {RLHF}: {Scaling} {Reinforcement} {Learning} from {Human} {Feedback} with {AI} {Feedback}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Computation and Language" /><node TEXT="Computer Science - Machine Learning" /></node><node TEXT="Right for the {Right} {Reasons}: {Training} {Differentiable} {Models} by {Constraining} their {Explanations}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Demande CCAI phase II" /><node TEXT="Statistics - Machine Learning" /></node><node TEXT="Strategic {Classification} is {Causal} {Modeling} in {Disguise}"><node TEXT="Lecture début de projet" /><node TEXT="Recommandé Audrey" /></node><node TEXT="Stochastic {Multi}-{Armed}-{Bandit} {Problem} with {Non}-stationary {Rewards}"><node TEXT="MAB" /><node TEXT="Non-stationary" /><node TEXT="Recommandé Audrey" /></node><node TEXT="General intelligence requires rethinking exploration"><node TEXT="Demande CCAI phase II" /></node><node TEXT="Evolutionary games on graphs"><node TEXT="Condensed Matter - Statistical Mechanics" /><node TEXT="Février" /><node TEXT="Game Theory" /><node TEXT="Nonlinear Sciences - Adaptation and Self-Organizing Systems" /><node TEXT="Quantitative Biology - Populations and Evolution" /><node TEXT="Review" /></node><node TEXT="Feedback {Loop} and {Bias} {Amplification} in {Recommender} {Systems}"><node TEXT="Computer Science - Information Retrieval" /><node TEXT="Demande CCAI phase II" /></node><node TEXT="Multi-{Player} {Bandits}: {The} {Adversarial} {Case}"><node TEXT="Recommandé Audrey" /></node><node TEXT="Old {Dog} {Learns} {New} {Tricks}: {Randomized} {UCB} for {Bandit} {Problems}" /><node TEXT="Prediction and {Statistical} {Inference} in {Feedback} {Loops}" /><node TEXT="Performative {Prediction}"><node TEXT="Lecture début de projet" /><node TEXT="Recommandé Audrey" /></node><node TEXT="Population-based {Evaluation} in {Repeated} {Rock}-{Paper}-{Scissors} as a {Benchmark} for {Multiagent} {Reinforcement} {Learning}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="MARL" /><node TEXT="RPS" /></node><node TEXT="Goodhart's {Law} in {Reinforcement} {Learning}"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Feedback loop" /><node TEXT="MDP" /><node TEXT="RL" /></node><node TEXT="Learning to {Communicate} with {Deep} {Multi}-{Agent} {Reinforcement} {Learning}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Computer Science - Multiagent Systems" /></node><node TEXT="Improving {Model} {Robustness} by {Adaptively} {Correcting} {Perturbation} {Levels} with {Active} {Queries}"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Demande CCAI phase II" /></node><node TEXT="Iterated {Prisoner}’s {Dilemma} contains strategies that dominate any evolutionary opponent"><node TEXT="Game Theory" /><node TEXT="Lecture début de projet" /><node TEXT="Prisoner's Dilema" /><node TEXT="Recommandé Audrey" /></node><node TEXT="Learning {Algorithms} for {Active} {Learning}"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Demande CCAI phase II" /></node><node TEXT="{LOQA}: {LEARNING} {WITH} {OPPONENT} {Q}-{LEARNING} {AWARENESS}"><node TEXT="Game Theory" /><node TEXT="Lecture début de projet" /><node TEXT="Prisoner's Dilema" /><node TEXT="RL" /><node TEXT="Recommandé Audrey" /></node><node TEXT="Metric-{Fair} {Active} {Learning}"><node TEXT="Demande CCAI phase II" /></node><node TEXT="Maximum-{Entropy} {Multi}-{Agent} {Dynamic} {Games}: {Forward} and {Inverse} {Solutions}"><node TEXT="Computer Science - Robotics" /><node TEXT="Mathematics - Optimization and Control" /></node><node TEXT="Planning and acting in partially observable stochastic domains"><node TEXT="Demande CCAI phase II" /></node><node TEXT="Open-ended {Learning} in {Symmetric} {Zero}-sum {Games}"><node TEXT="Février" /><node TEXT="Game Theory" /><node TEXT="Maxime" /><node TEXT="Zero-sum Games" /></node><node TEXT="Partial monitoring"><node TEXT="Demande CCAI phase II" /></node><node TEXT="Performative {Prediction} in a {Stateful} {World}"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Demande CCAI phase II" /></node><node TEXT="Robust agents learn causal world models"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Lecture début de projet" /><node TEXT="Recommandé Audrey" /></node><node TEXT="Situational {Awareness}"><node TEXT="LLM" /></node><node TEXT="{rStar}-{Math}: {Small} {LLMs} {Can} {Master} {Math} {Reasoning} with {Self}-{Evolved} {Deep} {Thinking}"><node TEXT="Computer Science - Computation and Language" /><node TEXT="LLM" /></node><node TEXT="Tracking the {Risk} of {Machine} {Learning} {Systems} with {Partial} {Monitoring}"><node TEXT="Demande CCAI phase II" /></node><node TEXT="{VLSlice}: {Interactive} {Vision}-and-{Language} {Slice} {Discovery}"><node TEXT="Computer Science - Computation and Language" /><node TEXT="Computer Science - Computer Vision and Pattern Recognition" /><node TEXT="Computer Science - Human-Computer Interaction" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Demande CCAI phase II" /></node><node TEXT="Considerations for addressing bias in artificial intelligence for health equity"><node TEXT="Demande CCAI phase II" /></node><node TEXT="Counterfactual {Risk} {Assessments}, {Evaluation}, and {Fairness}"><node TEXT="Computer Science - Computers and Society" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Lecture début de projet" /><node TEXT="Recommandé Audrey" /><node TEXT="Statistics - Applications" /><node TEXT="Statistics - Machine Learning" /><node TEXT="Statistics - Methodology" /></node><node TEXT="Convergence to {Nash} {Equilibrium}: {A} {Comparative} {Study} of {Rock}-{Paper}-{Scissors} {Algorithms}" /><node TEXT="Apprentissage par {Renforcement}" /><node TEXT="A {Survey} on {Multi}-player {Bandits}" /><node TEXT="A machine learning approach for online automated optimization of super-resolution optical microscopy"><node TEXT="Demande CCAI phase II" /></node><node TEXT="A {General} {Theoretical} {Paradigm} to {Understand} {Learning} from {Human} {Preferences}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Demande CCAI phase II" /><node TEXT="Statistics - Machine Learning" /></node><node TEXT="A {Game}-{Theoretic} {Perspective} on {Risk}-{Sensitive}{\textbackslash} {Reinforcement} {Learning}"><node TEXT="Demande CCAI phase II" /></node><node TEXT="3-dynamic\_programming" /><node TEXT="A {Classification} of {Feedback} {Loops} and {Their} {Relation} to {Biases} in {Automated} {Decision}-{Making} {Systems}"><node TEXT="Feedback loop" /><node TEXT="Lecture début de projet" /><node TEXT="Recommandé Audrey" /><node TEXT="Review" /></node><node TEXT="Classes of {Multiagent} {Q}-learning {Dynamics}  with -greedy {Exploration}"><node TEXT="Cycle" /><node TEXT="Game Theory" /><node TEXT="Important" /><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /><node TEXT="Prisoner's Dilema" /></node><node TEXT="A {Survey} and {Critique} of {Multiagent} {Deep} {Reinforcement} {Learning}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /></node><node TEXT="A {Survey} of {Learning} in {Multiagent} {Environments}: {Dealing} with {Non}-{Stationarity}"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Game Theory" /><node TEXT="Important" /><node TEXT="Mars 2025" /><node TEXT="Rewiev" /></node><node TEXT="{MAC}-{PO}: {Multi}-{Agent} {Experience} {Replay} via {Collective} {Priority} {Optimization}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /></node><node TEXT="Independent reinforcement learners in cooperative {Markov} games: a survey regarding coordination problems"><node TEXT="Cycle" /><node TEXT="Games" /><node TEXT="Mars 2025" /></node><node TEXT="The {Dynamics} of {Reinforcement} {Learning} in {Cooperative} {Multiagent} {Systems}"><node TEXT="Cycle" /><node TEXT="Multi-agent" /></node><node TEXT="Naive {Algorithmic} {Collusion}: {When} {Do} {Bandit} {Learners} {Cooperate} and {When} {Do} {They} {Compete}?"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Economics - General Economics" /><node TEXT="Epsillon" /><node TEXT="Important" /><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /><node TEXT="Quantitative Finance - Economics" /></node><node TEXT="All learning is local: {Multi}-agent learning in global reward games"><node TEXT="Game Theory" /><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /></node><node TEXT="Fair {Multi}-{Agent} {Bandits}"><node TEXT="Computer Science - Computers and Society" /><node TEXT="Computer Science - Distributed" /><node TEXT="Parallel" /><node TEXT="and Cluster Computing" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /><node TEXT="fairness" /></node><node TEXT="{MULTI}-{AGENT} {REINFORCEMENT} {LEARNING} {FOR} {NONZERO}-{SUM} {MARKOV} {GAMES}"><node TEXT="Game Theory" /><node TEXT="Mars 2025" /></node><node TEXT="Multi-armed bandit games"><node TEXT="Cycle" /><node TEXT="Game Theory" /><node TEXT="MAB" /><node TEXT="Mars 2025" /></node><node TEXT="Decision {Market} {Based} {Learning} {For} {Multi}-agent {Contextual} {Bandit} {Problems}"><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Emergent" /><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /></node><node TEXT="On the {Complexity} of {Multi}-{Agent} {Decision} {Making}: {From} {Learning} in {Games} to {Partial} {Monitoring}"><node TEXT="Game Theory" /><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /></node><node TEXT="Learning in {Multi}-{Player} {Stochastic} {Games}"><node TEXT="Game Theory" /><node TEXT="Mars 2025" /><node TEXT="Multi-player" /></node><node TEXT="Contextual {Games}: {Multi}-{Agent} {Learning} with {Side} {Information}" /><node TEXT="Fair {Probabilistic} {Multi}-{Armed} {Bandit} {With} {Applications} to {Network} {Optimization}"><node TEXT="Energy harvesting" /><node TEXT="Machine learning" /><node TEXT="Mars 2025" /><node TEXT="Minimax techniques" /><node TEXT="Multi-player" /><node TEXT="Probabilistic logic" /><node TEXT="Probabilistic multi-armed bandit" /><node TEXT="Throughput" /><node TEXT="Wireless communication" /><node TEXT="Wireless sensor networks" /><node TEXT="explore-then-commit" /><node TEXT="fairness constraint" /><node TEXT="max-min fairness" /><node TEXT="online learning" /><node TEXT="optimism in the face of uncertainty" /></node><node TEXT="Risk-{Aware} {Multi}-{Agent} {Multi}-{Armed} {Bandits}" /><node TEXT="Coordinated {Versus} {Decentralized} {Exploration} {In} {Multi}-{Agent} {Multi}-{Armed} {Bandits}"><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /><node TEXT="Multi-player" /></node><node TEXT="Modelling {Cournot} {Games} as {Multi}-agent {Multi}-armed {Bandits}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Economics - Econometrics" /><node TEXT="Game Theory" /><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /><node TEXT="Nash equilibrium" /></node><node TEXT="One for {All} and {All} for {One}: {Distributed} {Learning} of {Fair} {Allocations} {With} {Multi}-{Player} {Bandits}"><node TEXT="Games" /><node TEXT="Information theory" /><node TEXT="Mars 2025" /><node TEXT="Multi-player" /><node TEXT="Multi-player bandits" /><node TEXT="Protocols" /><node TEXT="Quality of service" /><node TEXT="Resource management" /><node TEXT="Task analysis" /><node TEXT="Throughput" /><node TEXT="distributed learning" /><node TEXT="fairness" /><node TEXT="online learning" /><node TEXT="resource allocation" /></node><node TEXT="Regret {Lower} {Bounds} in {Multi}-agent {Multi}-armed {Bandit}"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mars 2025" /><node TEXT="Multi-player" /><node TEXT="Statistics - Machine Learning" /></node><node TEXT="Distributed {Multi}-{Player} {Bandits} - a {Game} of {Thrones} {Approach}"><node TEXT="Mars 2025" /><node TEXT="Multi-player" /></node><node TEXT="Cooperative {Multi}-player {Bandit} {Optimization}"><node TEXT="Congestion game" /><node TEXT="Equilibrium" /><node TEXT="MAB" /><node TEXT="Mars 2025" /><node TEXT="Multi-player" /><node TEXT="Public good game" /></node><node TEXT="Proceedings {Of} {The} {International} {Congress} {Of} {Mathematicians} 2018 ({Icm} 2018) ({In} 4 {Volumes})"><node TEXT="Mars 2025" /><node TEXT="Mathematics / Applied" /><node TEXT="Mathematics / General" /><node TEXT="Mathematics / Research" /><node TEXT="Multi-player" /><node TEXT="RPS" /></node><node TEXT="My {Fair} {Bandit}: {Distributed} {Learning} of {Max}-{Min} {Fairness} with {Multi}-player {Bandits}"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Feedback loop" /><node TEXT="MAB" /><node TEXT="Mars 2025" /><node TEXT="Multi-player" /></node><node TEXT="Bandit based centralized matching in two-sided markets for peer to peer lending"><node TEXT="Computer Science - Machine Learning" /><node TEXT="MAB" /><node TEXT="Mars 2025" /><node TEXT="Pricing" /></node><node TEXT="{DOCTOR} {OF} {PHILOSOPHY} {COMPUTER} {SCIENCE}"><node TEXT="Mars 2025" /></node><node TEXT="Online {Recommendations} for {Agents} with {Discounted} {Adaptive} {Preferences}"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Information Retrieval" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="EXP3" /><node TEXT="MAB" /><node TEXT="Multi-agent" /></node><node TEXT="Conformist social learning leads to self-organised prevention against adverse bias in risky decision making"><node TEXT="Feedback loop" /><node TEXT="MAB" /><node TEXT="Mars 2025" /><node TEXT="collective behaviour" /><node TEXT="conformity" /><node TEXT="hot stove effect" /><node TEXT="reinforcement learning" /><node TEXT="risky decision making" /><node TEXT="social learning" /></node><node TEXT="Competitive {Pricing} {Using} {Model}-{Based} {Bandits}"><node TEXT="Game Theory" /><node TEXT="Multi-agent" /><node TEXT="Pricing" /></node><node TEXT="Modelling {Agent} {Decision} {Making} in {Agent}-based {Simulation} - {Analysis} {Using} an {Economic} {Technology} {Uptake} {Model}"><node TEXT="Evolutionnary game" /><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /></node><node TEXT="Improving {Spectral} {Efficiency} of {Wireless} {Networks} through {Democratic} {Spectrum} {Sharing}"><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Computer Science - Networking and Internet Architecture" /><node TEXT="Computer Science - Systems and Control" /><node TEXT="Electrical Engineering and Systems Science - Systems and Control" /><node TEXT="Spectrum sharing" /></node><node TEXT="The {Closed} {Loop} {Between} {Opinion} {Formation} and {Personalized} {Recommendations}"><node TEXT="Analytical models" /><node TEXT="Art" /><node TEXT="Control systems" /><node TEXT="Data models" /><node TEXT="Epsillon" /><node TEXT="Feedback loop" /><node TEXT="Mars 2025" /><node TEXT="Mathematical model" /><node TEXT="Numerical models" /><node TEXT="Recommender systems" /><node TEXT="networked control systems" /></node><node TEXT="Photon-{Atom} {Hybrid} {Decision}-{Framework} with {Concurrent} {Exploration} {Acceleration}"><node TEXT="Exploration" /><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /></node><node TEXT="Dynamics of {Social} {Networks}: {Multi}-agent {Information} {Fusion}, {Anticipatory} {Decision} {Making} and {Polling}"><node TEXT="Electrical Engineering and Systems Science - Signal Processing" /><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /></node><node TEXT="Long-{Term} {Fairness} in {Sequential} {Multi}-{Agent} {Selection} with {Positive} {Reinforcement}"><node TEXT="Computer Science - Computers and Society" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Feedback loop" /><node TEXT="Mars 2025" /><node TEXT="Multi-agent" /><node TEXT="Statistics - Machine Learning" /></node><node TEXT="A {Dynamic} {Decision}-{Making} {Framework} {Promoting} {Long}-{Term} {Fairness}" /><node TEXT="Bandit {Learning} with {Delayed} {Impact} of {Actions}"><node TEXT="Bandit" /><node TEXT="Feedback loop" /><node TEXT="Mars 2025" /></node><node TEXT="Balanced and {Incentivized} {Learning} with {Limited} {Shared} {Information} in {Multi}-agent {Multi}-armed {Bandit}" /><node TEXT="{SIC}-{MMAB}: {Synchronisation} {Involves} {Communication} in {Multiplayer} {Multi}-{Armed} {Bandits}"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Statistics - Machine Learning" /></node><node TEXT="On the convergence of policy gradient methods to {Nash} equilibria in general stochastic games"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mathematics - Optimization and Control" /></node><node TEXT="Riemannian stochastic optimization methods avoid strict saddle points"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mathematics - Optimization and Control" /></node><node TEXT="The equivalence of dynamic and strategic stability under regularized learning in games"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mathematics - Optimization and Control" /></node><node TEXT="On the discrete-time origins of the replicator dynamics: {From} convergence to instability and chaos"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Mathematics - Dynamical Systems" /></node><node TEXT="A geometric decomposition of finite games: {Convergence} vs. recurrence under exponential weights"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mathematics - Optimization and Control" /></node><node TEXT="Tamed {Langevin} sampling under weaker conditions"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Computer Science - Numerical Analysis" /><node TEXT="Mathematics - Numerical Analysis" /><node TEXT="Mathematics - Optimization and Control" /><node TEXT="Mathematics - Probability" /><node TEXT="Statistics - Machine Learning" /></node><node TEXT="Nested replicator dynamics, nested logit choice, and similarity-based learning"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /></node><node TEXT="The rate of convergence of {Bregman} proximal methods: {Local} geometry vs. regularity vs. sharpness"><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mathematics - Optimization and Control" /></node><node TEXT="Définition de projet" /><node TEXT="Evolutionary game theory and multi-agent reinforcement learning"><node TEXT="Battle of sexes" /><node TEXT="Evolutionnary game" /><node TEXT="Game Theory" /><node TEXT="MARL" /><node TEXT="Nash equilibrium" /><node TEXT="Prisoner's Dilema" /><node TEXT="evolutionary stable strategies" /></node><node TEXT="Evolutionary {Dynamics} of {Multi}-{Agent} {Learning}: {A} {Survey}"><node TEXT="Feedback loop" /><node TEXT="MARL" /><node TEXT="Review" /></node><node TEXT="Reinforcement {Learning}: {State}-of-the-{Art}"><node TEXT="Février" /><node TEXT="Game Theory" /><node TEXT="Livre" /><node TEXT="RL" /></node><node TEXT="Emergent {Tool} {Use} {From} {Multi}-{Agent} {Autocurricula}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Emergent" /><node TEXT="MARL" /><node TEXT="Statistics - Machine Learning" /></node><node TEXT="Equilibrium {Selection} for {Multi}-agent {Reinforcement} {Learning}: {A} {Unified} {Framework}"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Equilibrium" /><node TEXT="MARL" /><node TEXT="Mathematics - Optimization and Control" /><node TEXT="Theory" /></node><node TEXT="Test of {Significance} {When} {Data} are {Curves}" /><node TEXT="An {Overview} of {Multi}-{Agent} {Reinforcement} {Learning} from {Game} {Theoretical} {Perspective}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Feedback loop" /><node TEXT="Game Theory" /><node TEXT="MARL" /><node TEXT="Matrix game" /><node TEXT="Normal-form game" /><node TEXT="Review" /></node><node TEXT="Leveraging {Observations} in {Bandits}: {Between} {Risks} and {Benefits}"><node TEXT="Audrey" /><node TEXT="Bandit" /></node><node TEXT="Cyclic dominance in evolutionary games: {A} review"><node TEXT="Closed Orbits" /><node TEXT="Complex Ginzburg-Landau Equation" /><node TEXT="Computer Science - Social and Information Networks" /><node TEXT="Condensed Matter - Statistical Mechanics" /><node TEXT="Cycle" /><node TEXT="Game Theory" /><node TEXT="Heteroclininc Cycles" /><node TEXT="Hopf Bifurcation" /><node TEXT="May-Leonard Model" /><node TEXT="Nonlinear Sciences - Adaptation and Self-Organizing Systems" /><node TEXT="Physics - Physics and Society" /><node TEXT="Prisoner's Dilema" /><node TEXT="Quantitative Biology - Populations and Evolution" /><node TEXT="RPS" /><node TEXT="Review" /></node><node TEXT="The topology of the 2x2 games: a new periodic table"><node TEXT="Février" /><node TEXT="Game Theory" /><node TEXT="Important" /><node TEXT="Matric game" /><node TEXT="Review" /></node><node TEXT="Online {Learning} in {Iterated} {Prisoner}'s {Dilemma} to {Mimic} {Human} {Behavior}"><node TEXT="Bandit" /><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="MARL" /><node TEXT="Prisoner's Dilema" /><node TEXT="Q-Learning" /><node TEXT="Quantitative Biology - Neurons and Cognition" /><node TEXT="Recommandé Audrey" /></node><node TEXT="Accelerated regularized learning in finite {N}-person games"><node TEXT="Bandit" /><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Congestion game" /><node TEXT="Mathematics - Optimization and Control" /></node><node TEXT="A unified stochastic approximation framework for learning in games"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Mathematics - Optimization and Control" /></node><node TEXT="On {Shallow} {Planning} {Under} {Partial} {Observability}" /><node TEXT="Learning with {Bandit} {Feedback} in {Potential} {Games}"><node TEXT="Bandit" /><node TEXT="EXP3" /><node TEXT="Epsillon" /><node TEXT="Feedback loop" /><node TEXT="Important" /></node><node TEXT="A {Survey} on {Causal} {Reinforcement} {Learning}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Machine Learning" /></node><node TEXT="Efficient {Multiagent} {Planning} via {Shared} {Action} {Suggestions}"><node TEXT="Computer Science - Multiagent Systems" /></node><node TEXT="The {Complexity} of {Decentralized} {Control} of {Markov} {Decision} {Processes}"><node TEXT="Computer Science - Artificial Intelligence" /></node><node TEXT="Distributed {Output}-{Feedback} {Control} of {Nonlinear} {Multi}-{Agent} {Systems}"><node TEXT="Cyclic-small-gain method" /><node TEXT="Decentralized control" /><node TEXT="Multi-agent systems" /><node TEXT="Nonlinear systems" /><node TEXT="Observers" /><node TEXT="Robustness" /><node TEXT="Topology" /><node TEXT="distributed control" /><node TEXT="nonlinear systems" /><node TEXT="output agreement" /></node><node TEXT="Memory-{Bounded} {Dynamic} {Programming} for {DEC}-{POMDPs}" /><node TEXT="Multi-{Agent} {Reinforcement} {Learning}: {A} {Review} of {Challenges} and {Applications}" /><node TEXT="An {Empirical} {Evaluation} of {Thompson} {Sampling}" /><node TEXT="Reinforcement learning: an introduction"><node TEXT="Reinforcement learning" /></node><node TEXT="3-exploration\_exploitation" /><node TEXT="Large {Language} {Model} agents can coordinate beyond human scale"><node TEXT="Feedback loop" /><node TEXT="LLM" /><node TEXT="Multi-agent" /><node TEXT="Negotiation" /><node TEXT="Physics - Physics and Society" /></node><node TEXT="Paths to {Equilibrium} in {Games}"><node TEXT="Computer Science - Artificial Intelligence" /><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Machine Learning" /><node TEXT="Equilibrium" /><node TEXT="MARL" /><node TEXT="Theory" /></node><node TEXT="1 {Recap}: {Diﬀerence} between {Experts} and {Bandits}"><node TEXT="EXP3" /><node TEXT="O{\textasciicircum}2/3" /></node><node TEXT="Physics and {Ecology} of {Rock}-{Paper}-{Scissors} {Game}"><node TEXT="Dimensional Lattice" /><node TEXT="Feedback loop" /><node TEXT="Interact Particle System" /><node TEXT="Press Perturbation" /><node TEXT="Prey Density" /><node TEXT="RPS" /><node TEXT="Voter Model" /></node><node TEXT="Volunteering leads to rock–paper–scissors dynamics in a public goods game"><node TEXT="Application" /><node TEXT="Cycle" /><node TEXT="Humanities and Social Sciences" /><node TEXT="Public Good" /><node TEXT="RPS" /><node TEXT="Science" /><node TEXT="multidisciplinary" /></node><node TEXT="Learning in {Multi}-{Memory} {Games} {Triggers} {Complex} {Dynamics} {Diverging} from {Nash} {Equilibrium}"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Mathematics - Optimization and Control" /><node TEXT="Nonlinear Sciences - Chaotic Dynamics" /></node><node TEXT="Memory {Asymmetry} {Creates} {Heteroclinic} {Orbits} to {Nash} {Equilibrium} in {Learning} in {Zero}-{Sum} {Games}"><node TEXT="Computer Science - Computer Science and Game Theory" /><node TEXT="Computer Science - Multiagent Systems" /><node TEXT="Mathematics - Optimization and Control" /><node TEXT="Nonlinear Sciences - Chaotic Dynamics" /></node><node TEXT="The {Literature} {Review}: {A} {Few} {Tips} {On} {Conducting} {It} {\textbar} {Writing} {Advice}" /></node></map>